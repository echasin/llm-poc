{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbc7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import os\n",
    "import sqlite3\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import pinecone\n",
    "import langchain\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb26677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables from the .env file.\n",
    "load_dotenv()\n",
    "\n",
    "# Get the value of the API_KEY environment variable.\n",
    "api_key = os.getenv('api_key')\n",
    "environment = os.getenv('environment')\n",
    "index_name = os.getenv('index_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d260289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vector store object\n",
    "pinecone.init(api_key=api_key, environment=environment)\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e3bff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the embeddings object\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c3787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Similar Documents using Pinecone Index\n",
    "docsearch = Pinecone.from_existing_index(index_name, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc1e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"text-davinci-003\"\n",
    "llm = OpenAI(model=model_name)\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b586f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLite database setup\n",
    "conn = sqlite3.connect('pinecone_data.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816d24f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS data\n",
    "             (input_document TEXT, document_id TEXT, vector_id TEXT, search_result TEXT, update_timestamp TEXT)''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737773d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(query):\n",
    "    similar_docs = docsearch.similarity_search(query)\n",
    "    if not similar_docs:\n",
    "        return \"I don't know the information\"\n",
    "    answer = chain.run(input_documents=similar_docs, question=query)\n",
    "    \n",
    "    # Store data in SQLite\n",
    "    for doc in similar_docs:\n",
    "        c.execute(\"INSERT INTO data VALUES (?, ?, ?, ?, datetime('now'))\", \n",
    "                  (doc.page_content, doc.page_id, doc.vector_id, answer))\n",
    "    conn.commit()\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a76278",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is a Bills house?\"\n",
    "print(get_answer(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58fd045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close SQLite connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7982a46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To implement the \"Query the LLM and get formatted, validated, and corrected output\" part,\n",
    "# we need to modify the get_answer function to use the GuardrailsOutputParser. Steps:\n",
    "\n",
    "#Step1: we first create a RAIL spec that specifies that the output of the language model should be an object with three properties: \n",
    "## question_topic, \n",
    "## answer_topic, and \n",
    "## confidence_score where the confidence_score is a float with a valid range of 0 to 1.\n",
    "\n",
    "#Step2: Next, we create a GuardrailsOutputParser with the RAIL spec.\n",
    "\n",
    "##Step3: Finally, we modify the get_answer function to parse the output of the language model using the GuardrailsOutputParser. \n",
    "##Step4: The parsed output is then stored in the SQLite database.\n",
    "\n",
    "# Assumptions: \n",
    "## the output of the language model matches the structure specified in the RAIL spec. \n",
    "## If the output of the language model does not match this structure, the GuardrailsOutputParser will raise an error.\n",
    "## We may need to adjust the RAIL spec and the get_answer function based on the actual output of your language model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5d6ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from guardrails.guard import GuardrailsOutputParser\n",
    "\n",
    "# Create a RAIL spec\n",
    "rail_spec = \"\"\"\n",
    "<rail version=\"0.1\">\n",
    "<output>\n",
    " <object name=\"qa_info\">\n",
    " <string name=\"question_topic\" description=\"Topic of the question\" />\n",
    " <string name=\"answer_topic\" description=\"Topic of the answer\" />\n",
    " <float name=\"confidence_score\" format=\"valid-range: 0 1\" description=\"Confidence score for the match\" />\n",
    " </object>\n",
    "</output>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a9b35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GuardrailsOutputParser\n",
    "parser = GuardrailsOutputParser(rail_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(query):\n",
    "    similar_docs = docsearch.similarity_search(query)\n",
    "    if not similar_docs:\n",
    "        return \"I don't know the information\"\n",
    "    answer = chain.run(input_documents=similar_docs, question=query)\n",
    "    \n",
    "    # Parse the output using Guardrails\n",
    "    parsed_output = parser.parse(answer)\n",
    "    \n",
    "    # Store data in SQLite\n",
    "    for doc in similar_docs:\n",
    "        c.execute(\"INSERT INTO data VALUES (?, ?, ?, ?, datetime('now'))\", \n",
    "                  (doc.page_content, doc.page_id, doc.vector_id, parsed_output))\n",
    "    conn.commit()\n",
    "    \n",
    "    return parsed_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "persenv",
   "language": "python",
   "name": "persenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
